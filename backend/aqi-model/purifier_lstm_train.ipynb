{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "36c20612",
   "metadata": {},
   "source": [
    "# ðŸ’¨ Air Purifier Impact LSTM â€” Training Notebook\n",
    "\n",
    "Train an LSTM model to predict the air-quality impact of an **air purifier**,\n",
    "based on a 24-step time-series of environmental conditions.\n",
    "\n",
    "**Inputs (per time-step):** `current_aqi`, `current_pm25`, `room_size_sqft`, `ventilation_rate`\n",
    "\n",
    "**Outputs:** `pm25_reduction_percent`, `cadr_m3_per_hr`, `effective_coverage_sqft`\n",
    "\n",
    "Saves:\n",
    "- `models/purifier_lstm.pth`\n",
    "- `models/purifier_scaler.json`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7d7fb74",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import numpy as np\n",
    "import json\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "print(f\"PyTorch {torch.__version__}\")\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2875380a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ======================== CONFIG ========================\n",
    "SEQ_LEN      = 24       # 24 time-steps (hours)\n",
    "INPUT_DIM    = 4        # aqi, pm25, room_size, ventilation_rate\n",
    "OUTPUT_DIM   = 3        # pm25_red_pct, cadr, coverage\n",
    "HIDDEN_DIM   = 64\n",
    "NUM_LAYERS   = 2\n",
    "DROPOUT      = 0.2\n",
    "EPOCHS       = 100\n",
    "BATCH_SIZE   = 32\n",
    "LR           = 0.001\n",
    "NUM_SAMPLES  = 5000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91bf720f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===================== DATA GENERATION =====================\n",
    "def generate_purifier_data(num_samples: int):\n",
    "    \"\"\"\n",
    "    Generate synthetic time-series data for air purifier impact prediction.\n",
    "    Each sample is a 24-step sequence of environmental readings,\n",
    "    with the target being the expected impact of an air purifier.\n",
    "    Formula mirrors calculations.ts -> estimatePurifierImpact().\n",
    "    \"\"\"\n",
    "    np.random.seed(42)\n",
    "    X, y = [], []\n",
    "\n",
    "    for _ in range(num_samples):\n",
    "        base_aqi        = np.random.uniform(50, 400)\n",
    "        base_pm25       = np.random.uniform(20, 200)\n",
    "        room_size_sqft  = np.random.uniform(100, 800)   # Room size (sq ft)\n",
    "        ventilation     = np.random.uniform(0.5, 8.0)   # Air changes per hour\n",
    "\n",
    "        seq = []\n",
    "        for t in range(SEQ_LEN):\n",
    "            aqi  = base_aqi  + np.random.normal(0, 8) + t * np.random.normal(0, 0.3)\n",
    "            pm25 = base_pm25 + np.random.normal(0, 4) + t * np.random.normal(0, 0.15)\n",
    "            vent = max(0.1, ventilation + np.random.normal(0, 0.2))\n",
    "            seq.append([aqi, pm25, room_size_sqft, vent])\n",
    "\n",
    "        X.append(seq)\n",
    "\n",
    "        # ---------- Target calculation (mirrors calculations.ts) ----------\n",
    "        # Base purifier specs influenced by room size + AQI conditions\n",
    "        coverage_sqft        = 300 + np.random.random() * 300     # 300 â€“ 600 sqft\n",
    "        cadr                 = 250 + np.random.random() * 200     # 250 â€“ 450 mÂ³/hr\n",
    "        pm25_reduction_pct   = 60  + np.random.random() * 30      # 60 â€“ 90 %\n",
    "\n",
    "        # Adjustments based on room conditions\n",
    "        # Smaller rooms -> better coverage efficiency\n",
    "        room_factor = np.clip(500 / max(room_size_sqft, 100), 0.5, 1.5)\n",
    "        # Higher AQI -> slightly lower effective reduction (filter saturation)\n",
    "        aqi_factor  = np.clip(1.2 - (base_aqi / 500) * 0.4, 0.6, 1.2)\n",
    "        # Better ventilation -> slightly lower efficiency (more outdoor air influx)\n",
    "        vent_factor = np.clip(1.1 - ventilation * 0.03, 0.7, 1.1)\n",
    "\n",
    "        pm25_reduction_pct *= room_factor * aqi_factor * vent_factor\n",
    "        pm25_reduction_pct  = np.clip(pm25_reduction_pct, 30, 99)\n",
    "\n",
    "        cadr           *= room_factor\n",
    "        coverage_sqft  *= room_factor\n",
    "\n",
    "        y.append([pm25_reduction_pct, cadr, coverage_sqft])\n",
    "\n",
    "    return np.array(X, dtype=np.float32), np.array(y, dtype=np.float32)\n",
    "\n",
    "\n",
    "X, y = generate_purifier_data(NUM_SAMPLES)\n",
    "print(f\"X shape: {X.shape}  |  y shape: {y.shape}\")\n",
    "print(f\"Sample target: {y[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b60955eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =================== NORMALISATION ===================\n",
    "x_flat = X.reshape(-1, INPUT_DIM)\n",
    "x_min  = x_flat.min(axis=0)\n",
    "x_max  = x_flat.max(axis=0)\n",
    "y_min  = y.min(axis=0)\n",
    "y_max  = y.max(axis=0)\n",
    "\n",
    "X_norm = (X - x_min) / (x_max - x_min + 1e-8)\n",
    "y_norm = (y - y_min) / (y_max - y_min + 1e-8)\n",
    "\n",
    "# Train / Validation split (80 / 20)\n",
    "split = int(0.8 * NUM_SAMPLES)\n",
    "X_train, X_val = X_norm[:split], X_norm[split:]\n",
    "y_train, y_val = y_norm[:split], y_norm[split:]\n",
    "\n",
    "train_ds = TensorDataset(torch.FloatTensor(X_train), torch.FloatTensor(y_train))\n",
    "val_ds   = TensorDataset(torch.FloatTensor(X_val),   torch.FloatTensor(y_val))\n",
    "\n",
    "train_loader = DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=True)\n",
    "val_loader   = DataLoader(val_ds,   batch_size=BATCH_SIZE)\n",
    "\n",
    "print(f\"Train: {len(train_ds)} | Val: {len(val_ds)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6884f254",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==================== LSTM MODEL ====================\n",
    "class PurifierLSTM(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim, num_layers, dropout=0.2):\n",
    "        super().__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.num_layers = num_layers\n",
    "        self.lstm = nn.LSTM(\n",
    "            input_dim, hidden_dim, num_layers,\n",
    "            batch_first=True, dropout=dropout\n",
    "        )\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(hidden_dim, 32),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(32, output_dim),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_dim).to(x.device)\n",
    "        c0 = torch.zeros(self.num_layers, x.size(0), self.hidden_dim).to(x.device)\n",
    "        out, _ = self.lstm(x, (h0, c0))\n",
    "        return self.fc(out[:, -1, :])\n",
    "\n",
    "\n",
    "model     = PurifierLSTM(INPUT_DIM, HIDDEN_DIM, OUTPUT_DIM, NUM_LAYERS, DROPOUT).to(device)\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=LR)\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, patience=10, factor=0.5)\n",
    "\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "print(f\"PurifierLSTM  |  Parameters: {total_params:,}\")\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2babc1f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==================== TRAINING LOOP ====================\n",
    "train_losses = []\n",
    "val_losses   = []\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    # --- train ---\n",
    "    model.train()\n",
    "    epoch_loss = 0.0\n",
    "    for xb, yb in train_loader:\n",
    "        xb, yb = xb.to(device), yb.to(device)\n",
    "        pred = model(xb)\n",
    "        loss = criterion(pred, yb)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        epoch_loss += loss.item()\n",
    "    avg_train = epoch_loss / len(train_loader)\n",
    "    train_losses.append(avg_train)\n",
    "\n",
    "    # --- validate ---\n",
    "    model.eval()\n",
    "    v_loss = 0.0\n",
    "    with torch.no_grad():\n",
    "        for xb, yb in val_loader:\n",
    "            xb, yb = xb.to(device), yb.to(device)\n",
    "            v_loss += criterion(model(xb), yb).item()\n",
    "    avg_val = v_loss / len(val_loader)\n",
    "    val_losses.append(avg_val)\n",
    "    scheduler.step(avg_val)\n",
    "\n",
    "    if (epoch + 1) % 10 == 0:\n",
    "        print(f\"Epoch {epoch+1:3d}/{EPOCHS}  Train: {avg_train:.6f}  Val: {avg_val:.6f}\")\n",
    "\n",
    "print(\"\\nâœ… Training complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3edd175",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==================== LOSS CURVES ====================\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(train_losses, label=\"Train Loss\")\n",
    "plt.plot(val_losses,   label=\"Val Loss\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"MSE Loss\")\n",
    "plt.title(\"Purifier LSTM â€” Training Progress\")\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "384149f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==================== SAVE MODEL & SCALER ====================\n",
    "os.makedirs(\"models\", exist_ok=True)\n",
    "\n",
    "torch.save(model.state_dict(), \"models/purifier_lstm.pth\")\n",
    "\n",
    "scaler_data = {\n",
    "    \"x_min\": x_min.tolist(),\n",
    "    \"x_max\": x_max.tolist(),\n",
    "    \"y_min\": y_min.tolist(),\n",
    "    \"y_max\": y_max.tolist(),\n",
    "}\n",
    "with open(\"models/purifier_scaler.json\", \"w\") as f:\n",
    "    json.dump(scaler_data, f, indent=2)\n",
    "\n",
    "print(\"Saved  models/purifier_lstm.pth\")\n",
    "print(\"Saved  models/purifier_scaler.json\")\n",
    "print(f\"Model size: {os.path.getsize('models/purifier_lstm.pth') / 1024:.1f} KB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f7c3bdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==================== QUICK TEST ====================\n",
    "model.eval()\n",
    "test_x = torch.FloatTensor(X_norm[:1]).to(device)\n",
    "\n",
    "with torch.no_grad():\n",
    "    pred_norm = model(test_x).cpu().numpy()[0]\n",
    "\n",
    "pred_actual = pred_norm * (y_max - y_min) + y_min\n",
    "actual      = y[0]\n",
    "\n",
    "labels = [\"pm25_reduction_pct\", \"cadr_m3_per_hr\", \"coverage_sqft\"]\n",
    "\n",
    "print(\"=\" * 55)\n",
    "print(f\"{'Metric':<22} {'Predicted':>12} {'Actual':>12}\")\n",
    "print(\"-\" * 55)\n",
    "for lbl, p, a in zip(labels, pred_actual, actual):\n",
    "    print(f\"{lbl:<22} {p:>12.4f} {a:>12.4f}\")\n",
    "print(\"=\" * 55)\n",
    "\n",
    "# JSON output example\n",
    "result_json = {\n",
    "    \"type\": \"air_purifier\",\n",
    "    \"predictions\": {\n",
    "        lbl: round(float(p), 4) for lbl, p in zip(labels, pred_actual)\n",
    "    },\n",
    "}\n",
    "print(\"\\nJSON output:\")\n",
    "print(json.dumps(result_json, indent=2))"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
